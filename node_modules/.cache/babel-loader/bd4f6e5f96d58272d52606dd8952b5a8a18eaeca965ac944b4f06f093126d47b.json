{"ast":null,"code":"// export const getResponse = async (inputText) => {\n//     try {\n//       const response = await fetch('https://api.openai.com/v1/chat/completions', {\n//         method: 'POST',\n//         headers: {\n//           'Content-Type': 'application/json',\n//           'Authorization': `Bearer `\n//         },\n//         body: JSON.stringify({\n//           \"model\": \"gpt-3.5-turbo\", // or another model version\n//           \"messages\": [{ \"role\": \"user\", \"content\": inputText }],\n//           \"temperature\": 0.7\n//         })\n//       });\n//       if (!response.ok) {\n//         throw new Error(`HTTP error! status: ${response.status}`);\n//       }\n//       const data = await response.json();\n//       console.log('apiCalls', data); // Use the stored data for logging or other purposes\n//       return data;\n\n//     } catch (error) {\n//       console.error('Error calling OpenAI API:', error);\n//       return null;\n//     }\n//   };\n\nexport const getResponse = async inputText => {\n  try {\n    const response = await fetch('http://localhost:3080', {\n      method: 'POST',\n      headers: {\n        'Content-Type': 'application/json'\n      },\n      body: JSON.stringify({\n        inputText\n      })\n    });\n    if (!response.ok) {\n      throw new Error(`HTTP error! status: ${response.status}`);\n    }\n    const data = await response.json();\n    return data;\n  } catch (error) {\n    console.error('Error posting chat message:', error);\n  }\n};","map":{"version":3,"names":["getResponse","inputText","response","fetch","method","headers","body","JSON","stringify","ok","Error","status","data","json","error","console"],"sources":["/Users/edwinchalmers/turing_work/3mod/dungeongpt/src/apiCalls.js"],"sourcesContent":["// export const getResponse = async (inputText) => {\n//     try {\n//       const response = await fetch('https://api.openai.com/v1/chat/completions', {\n//         method: 'POST',\n//         headers: {\n//           'Content-Type': 'application/json',\n//           'Authorization': `Bearer `\n//         },\n//         body: JSON.stringify({\n//           \"model\": \"gpt-3.5-turbo\", // or another model version\n//           \"messages\": [{ \"role\": \"user\", \"content\": inputText }],\n//           \"temperature\": 0.7\n//         })\n//       });\n//       if (!response.ok) {\n//         throw new Error(`HTTP error! status: ${response.status}`);\n//       }\n//       const data = await response.json();\n//       console.log('apiCalls', data); // Use the stored data for logging or other purposes\n//       return data;\n      \n//     } catch (error) {\n//       console.error('Error calling OpenAI API:', error);\n//       return null;\n//     }\n//   };\n  \n  export const getResponse = async (inputText) => {\n    try {\n      const response = await fetch('http://localhost:3080', {\n        method: 'POST',\n        headers: {\n          'Content-Type': 'application/json'\n        },\n        body: JSON.stringify({ inputText })\n      });\n      if (!response.ok) {\n        throw new Error(`HTTP error! status: ${response.status}`);\n      }\n      const data = await response.json();\n      return data;\n    } catch (error) {\n      console.error('Error posting chat message:', error);\n    }\n  };"],"mappings":"AAAA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;;AAEE,OAAO,MAAMA,WAAW,GAAG,MAAOC,SAAS,IAAK;EAC9C,IAAI;IACF,MAAMC,QAAQ,GAAG,MAAMC,KAAK,CAAC,uBAAuB,EAAE;MACpDC,MAAM,EAAE,MAAM;MACdC,OAAO,EAAE;QACP,cAAc,EAAE;MAClB,CAAC;MACDC,IAAI,EAAEC,IAAI,CAACC,SAAS,CAAC;QAAEP;MAAU,CAAC;IACpC,CAAC,CAAC;IACF,IAAI,CAACC,QAAQ,CAACO,EAAE,EAAE;MAChB,MAAM,IAAIC,KAAK,CAAE,uBAAsBR,QAAQ,CAACS,MAAO,EAAC,CAAC;IAC3D;IACA,MAAMC,IAAI,GAAG,MAAMV,QAAQ,CAACW,IAAI,CAAC,CAAC;IAClC,OAAOD,IAAI;EACb,CAAC,CAAC,OAAOE,KAAK,EAAE;IACdC,OAAO,CAACD,KAAK,CAAC,6BAA6B,EAAEA,KAAK,CAAC;EACrD;AACF,CAAC","ignoreList":[]},"metadata":{},"sourceType":"module","externalDependencies":[]}